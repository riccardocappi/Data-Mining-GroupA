---
title: "HW_KNN"
author: "Data Divas"
date: "2024-03-27"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# KNN Homework

## Importing required libraries
```{r warning=FALSE,message=FALSE}
library(caret)
library(ggplot2)
library(dplyr)
library(factoextra)
library(FNN)
library(reshape2)
```

## Exploratory Data Analysis (EDA)
In this section we are going to perform a briefly data exploration:
- Quick view of the data summary
- Check for categorical variables and any missing values
- Analyzing correlation between variables
- Identifying outliers and high leverage points
- Applying PCA in order to see the explained variance of principal components

### Import dataset
```{r}
data = read.csv("wineq_train.csv")
summary(data)
```
We can see that variables like "free.sulfur.dioxide" and "total.sulfur.dioxide" have much higher values than the others variables such as "citric.acid" and "volatile.acidity", so it would be a good practice to scale the data.

### Checking for categorical and null values
```{r}
str(data)
```
We can see that there are no categorical variables.

```{r}
data[is.na(data)]
```
We can see that there are no missing values in the dataset.

### Correlation matrix
```{r}
corr <- round(cor(data), 2)

melted_cormat <- melt(corr)

ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
    midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Correlation") +
   theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
     size = 12, hjust = 1))+
  coord_fixed()

```
Looking at the correlation matrix we can see an high positive correlation value between "residual.sugar" and "density". Also an high negative correlation is noticeable between "density" and "alcohol".

### Most correlated pairs are: 
```{r}

# Filter pairs with different names
filtered_pairs <- melted_cormat[melted_cormat$Var1 != melted_cormat$Var2, ]

# Create a new column with sorted pairs inserting - between the names
filtered_pairs$pair <- apply(filtered_pairs[, c("Var1", "Var2")], 1,
                             function(x) paste(sort(x), collapse = "-"))

# Remove duplicates based on the sorted pair
filtered_pairs <- filtered_pairs[!duplicated(filtered_pairs$pair),]

# # Sort by absolute correlation value
filtered_pairs <- filtered_pairs[order(abs(filtered_pairs$value), decreasing = TRUE),]

filtered_pairs$pair <- NULL # to remove irrelevant column created
rownames(filtered_pairs) <- NULL # to remove indexes for the values from the last matrix

# Print the top correlated pairs with different names
head(filtered_pairs,10)
```

### Least correlated features with quality:
```{r}
# Calculate correlation between features and "quality" 
# except for the pair "quality-quality"
quality_correlation <- cor(data$quality, data[, -which(names(data) == "quality")])
least_correlated_indexes <- order(abs(quality_correlation))

# Pick the names of the top least correlated features
least_correlated_features <- names(data)[least_correlated_indexes]

# Create a data frame with feature names and their correlation values
result_df <- data.frame(Feature = least_correlated_features, Value =
                          quality_correlation[least_correlated_indexes])

head(result_df,10)
```

We can see variables like "citric.acid" or "free.sulfur.dioxide" has no correlation with the response variable "quality".

### Individuating outliers and high leverage point
```{r}
require(graphics)
#to have a look at graphs of features plotted against eachother
pairs(data, panel = panel.smooth)
```
We notice some outliers and high leverage points in the data particularly in "density","residual.sugar","free.sulfur.dioxide" and "fixed.acidity".

```{r}
#Storing outliers and hl points in a list. Later on I will remove them from data
outliers_hl_points <- c()
outliers_hl_points <- append(outliers_hl_points, 
                          which(data$density > 1.03))
outliers_hl_points <- append(outliers_hl_points, 
                          which(data$residual.sugar > 60))
outliers_hl_points <- append(outliers_hl_points, 
                          which(data$free.sulfur.dioxide > 250))
outliers_hl_points <- append(outliers_hl_points, 
                          which(data$fixed.acidity > 12))
```

For simplicity we individuated those points by looking at the scatter plots by hand.

```{r}
require(graphics)
#to show the scatterplot after removing outliers and high leverage points
pairs(data[-outliers_hl_points,], panel = panel.smooth)
```

### Apply PCA
```{r}
pca <- prcomp(data[-12], scale = TRUE)
fviz_screeplot(pca, addlabels = TRUE, ylim = c(0, 100))+ggtitle("Explained 
                                                                variance per component")
```
Since KNN performs better with few features (because of curse of dimensionality), we tried to perform PCA to see if the original dataset could be expressed with fewer components.
Based on the above plot, in order to get satisfying results, we would probably need more than 5 components.

```{r}
summary(pca)
```
## Fit KNN on training set and cross-validation
In this section we fit KNN model, trying several experiments:
- KNN and CV without any preprocessing applied
- KNN and CV with some feature engineering
- KNN and CV without outliers and hl points
- KNN and CV with PCA

### Helper functions
```{r}
RMSE <- function(y_true, y_pred){
  return(sqrt(mean((y_true - y_pred)^2)))
}
```

```{r}
fit_knn <- function(X_train, y_train, X_test, k_val){
  y_hat = knn.reg(train = X_train, test=X_test, y=y_train, k = k_val)
  y_hat = y_hat$pred
  return(y_hat)
}
```

```{r}
fit_knn_training_set <- function(X, y){
  k_range = seq(1, 50, by = 1)
  train_rmse <- c()
  
  for (k in k_range){
    y_hat = fit_knn(X, y, X, k)
    train_rmse <- append(train_rmse, RMSE(y, y_hat))
  }
  
  results_train_rmse <- data.frame(k = k_range, train_rmse=train_rmse)
  return(results_train_rmse)
}
```

```{r}
k_fold_cv <- function(X, y, train_rmse){
  set.seed(42)
  folds <- createFolds(y, k = 5, list = TRUE)
  cv_rmse <- c()
  k_range = seq(1, 50, by = 1)
  
  #perform k-fold-cross-validation for every value of k (1-50)
  for (k in k_range){ 
    cv_rmse_fold <- c()
    #iterates through every fold of the data
    for (i in 1:length(folds)) { 
      #unlist function flatten the list. Remember that folds is a list of lists
      train_indexes <- unlist(folds[-i]) 
      test_indexes <- unlist(folds[i])
      
      X_train <- X[train_indexes, ]
      y_train <- y[train_indexes]
      X_test <- X[test_indexes, ]
      y_test <- y[test_indexes]
      
      y_hat <- fit_knn(X_train, y_train, X_test, k)
      cv_rmse_fold <- append(cv_rmse_fold, RMSE(y_test, y_hat))
    }
    #append to the cv_rmse array the mean of the current fold with k-value
    cv_rmse <- append(cv_rmse, mean(cv_rmse_fold)) 
  }
  results_kfold <- data.frame(k = k_range, train_rmse, cv_rmse = cv_rmse)
  return(results_kfold)
  
}
```

```{r}
plot_training_cv_rmse <- function(results, train_rmse, cv_rmse){
  ggplot(results, aes(x = log(1/k), y = train_rmse, color = "Train RMSE")) +
  geom_line() +
  geom_point() +
  geom_line(aes(x = log(1/k), y = cv_rmse, color = "CV RMSE")) +
  geom_point(aes(x = log(1/k), y = cv_rmse, color = "CV RMSE")) +
  scale_x_continuous(labels = scales::scientific_format()) +
  labs(x = "log (1/K) (K of KNN)", y = "RMSE", color = "Data") +
  theme_minimal()
}
```

```{r}
find_best_k <- function(cv_rmse){
  minimum <- min(cv_rmse)
  print(paste('min cv_rmse:',minimum))
  print(paste('          k:', match( minimum , cv_rmse)))
}
```

```{r}
rm_feature <- function(X,omitted_features){
  X <- X[,!(names(X) %in% omitted_features) ]
  return(X)
}
```

### KNN and CV without preprocessing
```{r}
X <- data[, -12]
y <- data$quality
```

```{r}
results_train_rmse <- fit_knn_training_set(X, y)
train_rmse <- results_train_rmse$train_rmse
head(results_train_rmse,10)
```


### K-fold Cross Validation of KNN
```{r}
# The results of k-fold cv are returned as a dataframe.
results_kfold <- k_fold_cv(X, y, train_rmse)
cv_rmse = results_kfold$cv_rmse
head(results_kfold,10)
```

### Plots
```{r}
plot_training_cv_rmse(results_kfold, train_rmse, cv_rmse)
```
From the plot above we can see that as the model becomes more flexible, the training error decreases. However, the error computed with K-fold cross validation shows a U-shaped plot which is high even if the training error is low.
This suggests that we need to find a tradeoff between training error and cross-validation error to choose the optimal K value.

```{r}
#It finds best k in the case of fitting knn on data without feature engineering
find_best_k(cv_rmse)
```


### K-fold Cross Validation with feature engineering
We tried to process the data in the following way:
- scaling the data so that it has mean of 0 and standard deviation of 1
- removing "citric.acid" feature since it is the least correlated with the response variable
- removing "density" since it is very high correlated with "residual.sugar"

```{r}

X_fe <- as.data.frame(scale(X)) #scaling data

omitted_features <- c("citric.acid","density")
X_fe <- rm_feature(X_fe,omitted_features)
# X_val <- rm_feature(validation_data,omitted_features)

#Fitting knn on training set
results_train_rmse_fe <- fit_knn_training_set(X_fe, y)
train_rmse_fe = results_train_rmse_fe$train_rmse

#Fitting knn with cross validation
results_kfold_fe <- k_fold_cv(X_fe, y, train_rmse_fe)
cv_rmse_fe <- results_kfold_fe$cv_rmse

plot_training_cv_rmse(results_kfold_fe, train_rmse_fe, cv_rmse_fe)

```
```{r}
# Find best k
find_best_k(cv_rmse_fe)
```


## K-fold Cross Validation without outliers and hl points
```{r}
X_without_outliers <- data[-outliers_hl_points, -12]
y_without_outliers <- y[-outliers_hl_points]

#Fitting knn on training set
results_train_rmse_outliers <- fit_knn_training_set(X_without_outliers, 
                                                    y_without_outliers)
train_rmse_outliers = results_train_rmse_fe$train_rmse

#Fitting knn with cross validation
results_kfold_outliers <- k_fold_cv(X_without_outliers, 
                                    y_without_outliers, 
                                    train_rmse_outliers)
cv_rmse_outliers <- results_kfold_outliers$cv_rmse

plot_training_cv_rmse(results_kfold_outliers, 
                      train_rmse_outliers, 
                      cv_rmse_outliers)
```



```{r}
# Find best k
find_best_k(cv_rmse_outliers)
```


## K-fold Cross Validation of KNN with PCA
```{r}

# Fit KNN on training set with PCA

pc_data <- as.data.frame(pca$x)
components <- 7
X_pca <- pc_data[,1:components]

results_pca <- fit_knn_training_set(X_pca, y)

pca_training_rmse <- results_pca$train_rmse
results_kfold_pca <- k_fold_cv(X_pca, y, pca_training_rmse)

cv_rmse_pca <- results_kfold_pca$cv_rmse
plot_training_cv_rmse(results_kfold_pca, pca_training_rmse, cv_rmse_pca)

```
```{r}
# Find best k
find_best_k(cv_rmse_pca)
```

## Conclusions
- We notice how the model is performing slitghly better without using PCA;
- Taking out high leverage points or outliers always lead to slitghly worse results;
  - Current data points chosen to be removed seem the best one.
- Feature "citric_acid" seems the best feature to remove since it improves the perfomances in both cases. 
  - This doesn't hold for the case where we remove also other features.

## Other results: min cv_rmse calculated without taking out any data points
### Just scaled data
[1] "min cv_rmse: 0.706715970421997"
[1] "          k: 12"

### scaled, without citric acid 
[1] "min cv_rmse: 0.703730059806565"
[1] "          k: 15"

### scaled, without citric.acid and free.sulfur.dioxide
[1] "min cv_rmse: 0.720682765728945"
[1] "          k: 11"

### scaled, without density 
[1] "min cv_rmse: 0.708451354386089"
[1] "          k: 8"

### scaled, without residual.sugar
[1] "min cv_rmse: 0.705753479671869"
[1] "          k: 17"

### scaled, without citric acid, PCA with first 9 of 10 components (Best)
[1] "min cv_rmse: 0.703534208790268"
[1] "          k: 15"